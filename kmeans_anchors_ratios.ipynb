{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means anchors ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get COCO train 2017 annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (4.42.1)\n",
      "\u001b[31mfastai 1.0.60 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ANNOTATIONS_PATH = \"./annotations/instances_train2017.json\"\n",
    "\n",
    "!pip install tqdm\n",
    "if not os.path.exists(ANNOTATIONS_PATH):\n",
    "    !wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "    !unzip annotations_trainval2017.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32.0,\n",
       " 64.0,\n",
       " 128.0,\n",
       " 256.0,\n",
       " 512.0,\n",
       " 40.31747359663594,\n",
       " 80.63494719327188,\n",
       " 161.26989438654377,\n",
       " 322.53978877308754,\n",
       " 645.0795775461751,\n",
       " 50.79683366298238,\n",
       " 101.59366732596476,\n",
       " 203.18733465192952,\n",
       " 406.37466930385904,\n",
       " 812.7493386077181]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# efficientdet default anchors sizes\n",
    "anchors_scales = [2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)]\n",
    "anchors_sizes = list(np.array([anchors_scale * np.array([32, 64, 128, 256, 512]) for anchors_scale in anchors_scales]).flatten())\n",
    "anchors_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get optimal anchors ratios using K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-23 13:50:46 Starting the calculation of the optimal anchors ratios\n",
      "2020-05-23 13:50:46 Reading annotations from ./annotations/instances_train2017.json\n",
      "2020-05-23 13:51:06 Extracting and preprocessing bounding boxes\n",
      "2020-05-23 13:51:11 Discarding 2 bounding boxes with size lower or equal to 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-23 13:51:11 K-Means (10 runs): 100%|████████████| 10/10 [01:36<00:00,  9.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-23 13:52:47 Best run avg. IoU: 80.48%\n",
      "Runs avg. IoU: 80.48% ± 0.00% (mean ± std. dev. of 10 runs, 0 skipped)\n",
      "2020-05-23 13:52:47 Avg. IoU between norm. anchors and bboxes: 80.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-23 13:52:47 Avg. IoU between bounding boxes and their most similar anchor: 62.63%\n",
      "2020-05-23 13:52:58 Number of bounding boxes without similar anchors (IoU < 0.5):  239153/859999 (27.81%)\n",
      "2020-05-23 13:52:58 Optimal anchors ratios: [(0.6, 1.5), (1.0, 1.0), (1.4, 0.7)]\n"
     ]
    }
   ],
   "source": [
    "from kmeans_anchors_ratios import get_optimal_anchors_ratios\n",
    "\n",
    "\n",
    "anchors_ratios = get_optimal_anchors_ratios(\n",
    "    ANNOTATIONS_PATH,\n",
    "    input_size=512,\n",
    "    normalizes_bboxes=True,\n",
    "    num_runs=10,\n",
    "    num_anchors_ratios=3,\n",
    "    max_iter=300,\n",
    "    min_size=0,\n",
    "    iou_threshold=0.5,\n",
    "    anchors_sizes=anchors_sizes,\n",
    "    decimals=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get anchors from anchors ratios and sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  19.2       ,   48.        ],\n",
       "       [  32.        ,   32.        ],\n",
       "       [  44.8       ,   22.4       ],\n",
       "       [  38.4       ,   96.        ],\n",
       "       [  64.        ,   64.        ],\n",
       "       [  89.6       ,   44.8       ],\n",
       "       [  76.8       ,  192.        ],\n",
       "       [ 128.        ,  128.        ],\n",
       "       [ 179.2       ,   89.6       ],\n",
       "       [ 153.6       ,  384.        ],\n",
       "       [ 256.        ,  256.        ],\n",
       "       [ 358.4       ,  179.2       ],\n",
       "       [ 307.2       ,  768.        ],\n",
       "       [ 512.        ,  512.        ],\n",
       "       [ 716.8       ,  358.4       ],\n",
       "       [  24.19048416,   60.47621039],\n",
       "       [  40.3174736 ,   40.3174736 ],\n",
       "       [  56.44446304,   28.22223152],\n",
       "       [  48.38096832,  120.95242079],\n",
       "       [  80.63494719,   80.63494719],\n",
       "       [ 112.88892607,   56.44446304],\n",
       "       [  96.76193663,  241.90484158],\n",
       "       [ 161.26989439,  161.26989439],\n",
       "       [ 225.77785214,  112.88892607],\n",
       "       [ 193.52387326,  483.80968316],\n",
       "       [ 322.53978877,  322.53978877],\n",
       "       [ 451.55570428,  225.77785214],\n",
       "       [ 387.04774653,  967.61936632],\n",
       "       [ 645.07957755,  645.07957755],\n",
       "       [ 903.11140856,  451.55570428],\n",
       "       [  30.4781002 ,   76.19525049],\n",
       "       [  50.79683366,   50.79683366],\n",
       "       [  71.11556713,   35.55778356],\n",
       "       [  60.9562004 ,  152.39050099],\n",
       "       [ 101.59366733,  101.59366733],\n",
       "       [ 142.23113426,   71.11556713],\n",
       "       [ 121.91240079,  304.78100198],\n",
       "       [ 203.18733465,  203.18733465],\n",
       "       [ 284.46226851,  142.23113426],\n",
       "       [ 243.82480158,  609.56200396],\n",
       "       [ 406.3746693 ,  406.3746693 ],\n",
       "       [ 568.92453703,  284.46226851],\n",
       "       [ 487.64960316, 1219.12400791],\n",
       "       [ 812.74933861,  812.74933861],\n",
       "       [1137.84907405,  568.92453703]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kmeans_anchors_ratios import get_anchors_from_ratios_and_sizes\n",
    "\n",
    "\n",
    "anchors = get_anchors_from_ratios_and_sizes(anchors_ratios, anchors_sizes)\n",
    "anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ANNOTATIONS_PATH) as f:\n",
    "    annotations = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 bounding boxes without similar anchors:\n",
      "[[251.87, 333.42, 125.94, 22.71], [236.2, 146.01, 26.17, 19.49], [377.68, 258.81, 13.28, 9.36], [484.33, 224.38, 34.03, 22.54], [162.27, 189.06, 29.63, 25.24]]\n"
     ]
    }
   ],
   "source": [
    "from kmeans_anchors_ratios import get_annotations_without_similar_anchors\n",
    "\n",
    "annotations_field = get_annotations_without_similar_anchors(\n",
    "    annotations,\n",
    "    anchors_ratios,\n",
    "    anchors_sizes,\n",
    "    input_size=512,\n",
    "    iou_threshold=0.5,\n",
    "    min_size=0,\n",
    ")\n",
    "bboxes_without_similar_anchors = [ann[\"bbox\"] for ann in annotations_field]\n",
    "# IMPORTANT: the bounding boxes are scaled according to the input_size before the comparison with the anchors but those returned are at original size\n",
    "# e.g. if a bounding box has width = height = 40, input_size=512 and the original image size is 5120,\n",
    "# the bounding box used to train the model is just 4x4 (and no anchor will have IoU > 50% with it)\n",
    "print(\"First 5 bounding boxes without similar anchors:\")\n",
    "print(bboxes_without_similar_anchors[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}